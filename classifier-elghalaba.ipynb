{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from classifier import *\n",
    "from preprocessing import *\n",
    "from staff_removal import *\n",
    "from helper_methods import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get paths of scaned and captured test cases #\n",
    "scanned_path = './test-cases/test-set-scanned/scanned'\n",
    "captured_path = './test-cases/test-set-camera-captured/captured'\n",
    "\n",
    "img_filenames = os.listdir(scanned_path)\n",
    "for i, fn in enumerate(img_filenames):\n",
    "    test_number = fn.split('.')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_img(img_path, output_path):\n",
    "    # 1. Read desired image #\n",
    "    img = cv2.imread(img_path, 0)\n",
    "    \n",
    "    # 2. Remove noise (odd pixels) from the image and save it #\n",
    "    img = cv2.fastNlMeansDenoising(img, None, 10, 7, 21)\n",
    "    cv2.imwrite('testing-output/{}/1. noise_removed.png'.format(output_path), img)\n",
    "\n",
    "    # 3. Binarize image using combination of (global + otsu) thresholding and save it #\n",
    "    threshold, img = cv2.threshold(img, 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "    cv2.imwrite('testing-output/{}/2. binarized.png'.format(output_path), img)\n",
    "\n",
    "    # 4. Return image shape (width, height) and processed image # \n",
    "    n, m = img.shape\n",
    "    return n, m, img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Steps of processing\n",
    "1. ~Apply Pre-processing~\n",
    "2. ~Remove Staff lines~\n",
    "3. ~Cut images into buckets~\n",
    "4. ~Get reference line for each bucket~\n",
    "5. ~Segment symbols, Sort them by x-value~\n",
    "6. Classify symbol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Loading dataset. This will take time ...\n",
      "finished processing:  a_1\n",
      "finished processing:  a_16\n",
      "finished processing:  a_16_flipped\n",
      "finished processing:  a_2\n",
      "finished processing:  a_2_flipped\n",
      "finished processing:  a_32\n",
      "finished processing:  a_4\n",
      "finished processing:  a_4_flipped\n",
      "finished processing:  a_8\n",
      "finished processing:  a_8_flipped\n",
      "finished processing:  b\n",
      "finished processing:  barline\n",
      "finished processing:  b_16\n",
      "finished processing:  b_16_flipped\n",
      "finished processing:  b_8\n",
      "finished processing:  b_8_flipped\n",
      "finished processing:  chord_2\n",
      "finished processing:  chord_3\n",
      "finished processing:  chord_3_2\n",
      "finished processing:  chord_special\n",
      "finished processing:  Clef\n",
      "finished processing:  d\n",
      "finished processing:  dot\n",
      "finished processing:  hash\n",
      "finished processing:  symbol_bb\n",
      "finished processing:  t_2\n",
      "finished processing:  t_4\n",
      "finished processing:  x\n",
      "Finished loading dataset.\n"
     ]
    }
   ],
   "source": [
    "print('Loading dataset. This will take time ...')\n",
    "features, labels = load_dataset('hog')\n",
    "print('Finished loading dataset.')\n",
    "\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(\n",
    "    features, labels, test_size=0.2, random_state=random_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "############## Training SVM ##############\n",
      "SVM accuracy: 99.40334128878283 %\n"
     ]
    }
   ],
   "source": [
    "model_name = 'SVM'\n",
    "model = run_experiment(train_features, test_features, train_labels, test_labels, model_name)\n",
    "\n",
    "filename = f'{model_name}.sav'\n",
    "pickle.dump(model, open(filename, 'wb'))\n",
    " \n",
    "# TODO: Use this line to load the model \n",
    "# model = pickle.load(open(filename, 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = './data-set/a_4'\n",
    "\n",
    "# img_filenames = os.listdir(path)\n",
    "# for i, fn in enumerate(img_filenames):\n",
    "#     if fn != '':\n",
    "#         img = cv2.imread(f'{path}/{fn}', 0)\n",
    "#         img = clean_and_cut(img)\n",
    "#         cv2.imwrite(f'{path}/{fn}', img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "IndentationError",
     "evalue": "expected an indented block (<ipython-input-9-f87bc3958256>, line 4)",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-9-f87bc3958256>\"\u001b[1;36m, line \u001b[1;32m4\u001b[0m\n\u001b[1;33m    elif label == 'a_2':\u001b[0m\n\u001b[1;37m       ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "direct_labels = ['x', 'b', 'Clef', 'dot', 'hash', 'd', 't_2', 't_4', 'symbol_bb', 'barline']\n",
    "\n",
    "direct_texts = {'x':'##', 'b':'&', 'hash':'#', 'd':'', 'symbol_bb':'&&', 'dot':'.', 'Clef':'', 't_2':'2', 't_4':'4', 'barline':''}\n",
    "\n",
    "def get_a_character(distance, line_spacing, flipped = 0):\n",
    "    # TODO: change it to chars array manipluation \n",
    "    # TODO: check 4.5\n",
    "\n",
    "    if flipped and distance < 2.75 * line_spacing:\n",
    "        return 'b'\n",
    "    if distance < flipped * (4.5 * line_spacing) + .25 * line_spacing:\n",
    "        return 'c'\n",
    "    if distance < flipped * (4.5 * line_spacing) + .75 * line_spacing:\n",
    "        return 'd'\n",
    "    if distance < flipped * (4.5 * line_spacing) + 1.25 * line_spacing:\n",
    "        return 'e'\n",
    "    if distance < flipped * (4.5 * line_spacing) + 1.75 * line_spacing:\n",
    "        return 'f'\n",
    "    if distance < flipped * (4.5 * line_spacing) + 2.25 * line_spacing:\n",
    "        return 'g'\n",
    "    if distance < flipped * (4.5 * line_spacing) + 2.75 * line_spacing:\n",
    "        return 'a'\n",
    "    if distance < flipped * (4.5 * line_spacing) + 3.25 * line_spacing:\n",
    "        return 'b'\n",
    "\n",
    "\n",
    "def text_operation(label, ref_line, line_spacing, y1, y2): \n",
    "    if label in direct_labels:\n",
    "        return direct_texts[label]\n",
    "        \n",
    "    if not(label.endsWith('flipped')): \n",
    "        distance = 0\n",
    "        if label.startsWith('a_'):\n",
    "            distance = ref_line - y2\n",
    "            character = get_a_character(distance, line_spacing)\n",
    "\n",
    "        if label == 'a_1':\n",
    "            return character + '/1'\n",
    "        if label == 'a_2':\n",
    "            return character + '/2'\n",
    "        if label == 'a_4':\n",
    "            return character + ''\n",
    "        if label == 'a_8':\n",
    "            return character + '/8'\n",
    "        if label == 'a_16':\n",
    "            return character + '/16'\n",
    "        if label == 'a_32':\n",
    "            return character + '/32'\n",
    "    else: # flipped\n",
    "        distance = 0\n",
    "        if label.startsWith('a_'):\n",
    "            distance = ref_line - y1\n",
    "            character = get_a_character(distance, line_spacing, 1)\n",
    "\n",
    "        if label.startsWith('a_2'):\n",
    "            return character + '2/2'\n",
    "        if label.startsWith('a_4'):\n",
    "            return character + '2'\n",
    "        if label.startsWith('a_8'):\n",
    "            return character + '8/2'\n",
    "        if label.startsWith('a_16'):\n",
    "            return character + '16/2'\n",
    "        if label.startsWith('a_32'):\n",
    "            return character + '32/2'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def cut_boundaries(cur_symbol, no_of_cuts, y2):\n",
    "    last_x = 0\n",
    "    cutted_boundaries = []\n",
    "    step = cur_symbol.shape[1] // no_of_cuts\n",
    "\n",
    "    for i in range(no_of_cuts):\n",
    "        cur = cur_symbol[:, last_x:last_x + step]\n",
    "        last_x += step\n",
    "\n",
    "        white = np.argwhere(cur == 255)\n",
    "        white = sorted(white, key=lambda x: x[0])\n",
    "\n",
    "        y_min, y_max = white[0][0], white[-1][0]\n",
    "        ret_boundary = [0, y_min, cur.shape[1] - 1, y_max]\n",
    "        \n",
    "        diff_y1, diff_y2 = cur.shape[0] - y_min, cur.shape[0] - y_max\n",
    "        ret_boundary[1] = y2 - diff_y1\n",
    "        ret_boundary[3] = y2 - diff_y2\n",
    "        \n",
    "        cutted_boundaries.append(ret_boundary)\n",
    "\n",
    "    return cutted_boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Threshold for line to be considered as an initial staff line #\n",
    "cnt = 0\n",
    "threshold = 0.8\n",
    "correct_labels = np.load('correct_labels.npy')\n",
    "\n",
    "for i in ['01', '02', '03', '04', '05', '06', '07', '08', '09', '10']:\n",
    "    try: \n",
    "        os.mkdir('testing-output/{}'.format(i)) \n",
    "    except OSError as error: \n",
    "        pass\n",
    "\n",
    "    f = open(\"testing-output/{i}.txt\", \"w\")\n",
    "\n",
    "    # Get image and its dimensions#\n",
    "    height, width, in_img = preprocess_img('{}/{}.png'.format(scanned_path, i), '{}'.format(i))\n",
    "    \n",
    "    # Get line thinkness and list of staff lines #\n",
    "    staff_lines_thicknesses, staff_lines = get_staff_lines(width, height, in_img, threshold)\n",
    "\n",
    "    # Remove staff lines from original image #\n",
    "    cleaned = remove_staff_lines(in_img, width, staff_lines, staff_lines_thicknesses)\n",
    "    cv2.imwrite('testing-output/{}/3. cleaned.png'.format(i), cleaned)\n",
    "    \n",
    "    # Get list of cutted buckets and cutting positions #\n",
    "    cut_positions, cutted = cut_image_into_buckets(cleaned, staff_lines)\n",
    "    \n",
    "    # Get reference line for each bucket #\n",
    "    ref_lines, lines_spacing = get_ref_lines(cut_positions, staff_lines)\n",
    "    \n",
    "    for it in range(len(cutted)):\n",
    "        cur_img = cutted[it].copy()\n",
    "        symbols_boundries = segmentation(cutted[it])\n",
    "        symbols_boundries.sort(key = lambda x: (x[0], x[1]))\n",
    "        \n",
    "        symbols = []\n",
    "        for boundry in symbols_boundries:\n",
    "            # Get the current symbol #\n",
    "            x1, y1, x2, y2 = boundry\n",
    "            cur_symbol = cutted[it][y1:y2+1, x1:x2+1]\n",
    "            \n",
    "            # Clean and cut #\n",
    "            cur_symbol = clean_and_cut(cur_symbol)\n",
    "            cur_symbol = 255 - cur_symbol\n",
    "\n",
    "            # Start prediction of the current symbol #\n",
    "            feature = extract_features(cur_symbol, 'hog')\n",
    "            label = model.predict([feature])\n",
    "            \n",
    "            if label == 'b_8' or label == 'b_8_flipped':\n",
    "                cutted_boundaries = cut_boundaries(cur_symbol, 2)\n",
    "            elif label == 'b_16' or label == 'b_16_flipped':\n",
    "                cutted_boundaries = cut_boundaries(cur_symbol, 4)\n",
    "            else \n",
    "                cutted_boundaries = cut_boundaries(cur_symbol, 1)\n",
    " \n",
    "            for cut_boundary in cut_boundaries:\n",
    "                ## TODO: text operations -> parameters(label, distance_to_the_ref_line => ref_line[it] - y2)\n",
    "                _, y1, _, y2 = cutted_boundary\n",
    "                text = text_operation(label, ref_lines[it], lines_spacing[it], y1, y2)\n",
    "                f.write(text)\n",
    "\n",
    "\n",
    "            if correct_labels[cnt] != label:    \n",
    "                print(cnt, label)\n",
    "            \n",
    "                plt.axis('off')\n",
    "                io.imshow(cur_symbol)\n",
    "                io.show()\n",
    "                \n",
    "            cnt+=1\n",
    "\n",
    "        f.write('\\n')\n",
    "    \n",
    "        cv2.imwrite(f'testing-output/{i}/4. cutted-{it + 1}.png', cutted[it])\n",
    "        cv2.imwrite(f'testing-output/{i}/5. cutted-segmented-{it + 1}.png', cur_img)\n",
    "\n",
    "    \n",
    "    f.close()        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}