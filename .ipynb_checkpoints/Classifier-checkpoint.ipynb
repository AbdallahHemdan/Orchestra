{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier  # MLP is an NN\n",
    "from sklearn import svm\n",
    "import numpy as np\n",
    "import argparse\n",
    "import imutils\n",
    "import cv2\n",
    "import os\n",
    "import skimage.io as io\n",
    "import random\n",
    "from skimage.transform import rotate\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_img(img):\n",
    "    return rotate(img, 180)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_dataset(folder_path):\n",
    "    fixed_path = folder_path + '_flipped'\n",
    "    if not os.path.exists(fixed_path):\n",
    "        os.makedirs(fixed_path)\n",
    "    else:\n",
    "        return\n",
    "        \n",
    "    img_filenames = os.listdir(folder_path)\n",
    "    for i, fn in enumerate(img_filenames):\n",
    "        path = os.path.join(folder_path, fn)\n",
    "        img = io.imread(path)\n",
    "        fixed_img = fix_img(img)\n",
    "        fixed_img_path = os.path.join(fixed_path, fn)\n",
    "        io.imsave(fixed_img_path, fixed_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [1, 2, 4, 8, 16, 32]:\n",
    "    fix_dataset('./Ours/a_' + str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge(img):\n",
    "    n, m = img.shape\n",
    "    print(n, m)\n",
    "    merged = np.zeros((n, m * 2))\n",
    "    print(merged.shape)\n",
    "    merged[:, 0:m] = merged[:, m:2*m] = img\n",
    "    \n",
    "    return merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bb():\n",
    "    b_path = './Ours/e'\n",
    "    bb_path = './Ours/bb'\n",
    "    if not os.path.exists(bb_path):\n",
    "        os.makedirs(bb_path)\n",
    "    else:\n",
    "        return\n",
    "    img_filenames = os.listdir(b_path)\n",
    "    for i, fn in enumerate(img_filenames):\n",
    "        path = os.path.join(folder_path, fn)\n",
    "        img = io.imread(path)\n",
    "        merged_img = merge(img)\n",
    "        merged_img_path = os.path.join(bb_path, fn)\n",
    "        io.imsave(merged_img_path, merged_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 42  \n",
    "target_img_size = (32, 32)\n",
    "random.seed(random_seed)\n",
    "np.random.seed(random_seed)\n",
    "\n",
    "def extract_raw_pixels(img):\n",
    "    return cv2.resize(img, target_img_size).flatten()\n",
    "\n",
    "def extract_hog_features(img):\n",
    "    img = cv2.resize(img, target_img_size)\n",
    "    win_size = (32, 32)\n",
    "    cell_size = (4, 4)\n",
    "    block_size_in_cells = (2, 2)\n",
    "    \n",
    "    block_size = (block_size_in_cells[1] * cell_size[1], block_size_in_cells[0] * cell_size[0])\n",
    "    block_stride = (cell_size[1], cell_size[0])\n",
    "    nbins = 9\n",
    "    hog = cv2.HOGDescriptor(win_size, block_size, block_stride, cell_size, nbins)\n",
    "    h = hog.compute(img)\n",
    "    h = h.flatten()\n",
    "    return h.flatten()\n",
    "\n",
    "def extract_features(img, feature_set='hog'):\n",
    "    if feature_set == 'hog':\n",
    "        return extract_hog_features(img)\n",
    "    else:\n",
    "        return extract_raw_pixels(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_directories():\n",
    "    directories = []\n",
    "    directories_filenames = os.listdir('./Ours')\n",
    "    \n",
    "    for i, fn in enumerate(directories_filenames):\n",
    "        directories.append(fn)\n",
    "        \n",
    "    return directories\n",
    "\n",
    "def load_dataset(feature_set='hog'):\n",
    "    labels = []\n",
    "    features = []\n",
    "    directories = get_directories()\n",
    "    \n",
    "    for dir_name in directories:\n",
    "        path_to_dataset = './Ours/' + dir_name\n",
    "        img_filenames = os.listdir(path_to_dataset)\n",
    "        \n",
    "        for i, fn in enumerate(img_filenames):\n",
    "            label = dir_name\n",
    "            labels.append(label)\n",
    "    \n",
    "            path = os.path.join(path_to_dataset, fn)\n",
    "            img = cv2.imread(path)\n",
    "            features.append(extract_features(img, feature_set))\n",
    "        \n",
    "        print('finished processing: ', dir_name)\n",
    "        \n",
    "    return features, labels\n",
    "\n",
    "classifiers = {\n",
    "    'SVM': svm.LinearSVC(random_state=random_seed),\n",
    "    'KNN': KNeighborsClassifier(n_neighbors=7),\n",
    "    'NN': MLPClassifier(solver='sgd', random_state=random_seed, hidden_layer_sizes=(500,), max_iter=20, verbose=1)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset. This will take time ...\n",
      "finished processing:  a_1\n",
      "finished processing:  a_16\n",
      "finished processing:  a_16_flipped\n",
      "finished processing:  a_1_flipped\n",
      "finished processing:  a_2\n",
      "finished processing:  a_2_flipped\n",
      "finished processing:  a_32\n",
      "finished processing:  a_32_flipped\n",
      "finished processing:  a_4\n",
      "finished processing:  a_4_flipped\n",
      "finished processing:  a_8\n",
      "finished processing:  a_8_flipped\n",
      "finished processing:  barline\n",
      "finished processing:  b_16\n",
      "finished processing:  b_8\n",
      "finished processing:  c\n",
      "finished processing:  d\n",
      "finished processing:  dot\n",
      "finished processing:  e\n",
      "finished processing:  f\n",
      "finished processing:  t_4_4\n",
      "finished processing:  z\n",
      "Finished loading dataset.\n"
     ]
    }
   ],
   "source": [
    "# Load dataset with extracted features\n",
    "print('Loading dataset. This will take time ...')\n",
    "features, labels = load_dataset('hog')\n",
    "print('Finished loading dataset.')\n",
    "\n",
    "# Since we don't want to know the performance of our classifier on images it has seen before\n",
    "# we are going to withhold some images that we will test the classifier on after training \n",
    "train_features, test_features, train_labels, test_labels = train_test_split(\n",
    "    features, labels, test_size=0.2, random_state=random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM  accuracy: 98.31387808041504 %\n"
     ]
    }
   ],
   "source": [
    "# SVM training\n",
    "svm = classifiers['SVM']\n",
    "svm.fit(train_features, train_labels)\n",
    "accuracy = svm.score(test_features, test_labels)\n",
    "print('SVM ', 'accuracy:', accuracy*100, '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['a_1', 'a_1', 'a_4', 'a_4'], dtype='<U12')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fn = ['1.png', '2.png', '3.png', '4.png']\n",
    "images = []\n",
    "for i in fn:\n",
    "    img = io.imread(i)\n",
    "    img = extract_features(img, 'hog')\n",
    "    images.append(img)\n",
    "svm.predict(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function will test all our classifiers on a specific feature set\n",
    "def run_experiment(feature_set):    \n",
    "    for model_name, model in classifiers.items():\n",
    "        print('############## Training', model_name, \"##############\")\n",
    "        # Train the model only on the training features\n",
    "        model.fit(train_features, train_labels)\n",
    "        \n",
    "        # Test the model on images it hasn't seen before\n",
    "        accuracy = model.score(test_features, test_labels)\n",
    "        \n",
    "        print(model_name, 'accuracy:', accuracy*100, '%')\n",
    "\n",
    "run_experiment('hog')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
